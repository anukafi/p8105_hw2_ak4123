p8105\_hw2\_ak4123
================

QUESTION 1
----------

Read & Clean Data

``` r
transit_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_integer(),
    ##   Route9 = col_integer(),
    ##   Route10 = col_integer(),
    ##   Route11 = col_integer(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

### About the data:

This dataset contains the information about NYC subway lines. It includes the line name, the staation name and location via longitude and latitude, along with what routes it serves. Also, whether the station has entry or not is included, along with the entrance type. The last piece of information included is whether it is ADA compliant. So far, I have cleaned the names of the data to be all lowercase, and in snake casing. I have included only the variables asked for, thus getting rid of the division name, exit only variable (which is dependent on the entry vairable), the information on staffing, the cross streets, and the longititudes and latitudes of the entrances and exits. (1868, 19) is the dimensions of this dataset. This means there are 1868 observations (rows) and 19 variables (columns). These data are not tidy. One example of this would be the mutiple, unnecessary columns for the routes (there are 11). This is redundant and excessive, and need to be condensed.

### Questions:

There are 465 distinct stations. There are 84 ADA compliant stations. The proportion of station entrances/exits without vending that allow entrance is 1. Thus, all station/entrances/exits without vending allow entrance.

Reformat data so that route number and route name are distinct variables.

``` r
transit_data_reformat = 
  transit_data %>%
  gather(key = route_number, value=route_name, route1:route11)

select(transit_data_reformat, route_name, station_name, line) %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name)
```

    ## # A tibble: 60 x 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # ... with 50 more rows

``` r
select(transit_data_reformat, route_name, station_name, line, ada) %>% 
  filter(route_name == "A", ada == "TRUE") %>% 
  distinct(line, station_name)
```

    ## # A tibble: 17 x 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

There are 60 distinct stations that serve the A train.

Of the stations that serve the A train, 17 are ADA compliant.

Read and clean the Mr. Trash Wheel sheet:

``` r
library(readxl)
mr_trash_data = 
  read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:M")) %>%
janitor::clean_names() %>%
filter(is.na(dumpster)) %>%
mutate(sports_balls = as.integer(round(sports_balls)))
```

Read and clean precipitation data for 2016 and 2017. For each, omit rows without precipitation data and add a variable year. Next, combine datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

``` r
sixteen_data = read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range = cell_rows(2:15)) %>%
janitor::clean_names() %>%
  mutate(year = 2016) %>%
filter(is.na(total))
  
seventeen_data = read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range = cell_rows(2:15)) %>%
  janitor::clean_names() %>%
filter(is.na(total))  %>%
mutate(year = 2017)

data_joined = bind_rows(sixteen_data, seventeen_data) %>%
mutate(month = month.name[as.integer(month)])
```

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables.

The total precipitation in 2017 was 0 inches for the data available.

The median number of sports balls in a dumpster in 2016 was balls.

``` r
# install.packages("devtools")
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (21f5ad1c) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)
data("brfss_smart2010")

BRFSS_data = brfss_smart2010 %>% 
 janitor::clean_names() %>%
filter(topic == "overall_health") %>% 
select(year:locationdesc, response, data_value)

spread(BRFSS_data, key = response, value = data_value)
```

    ## # A tibble: 0 x 3
    ## # ... with 3 variables: year <int>, locationabbr <chr>, locationdesc <chr>

create a new variable showing the proportion of responses that were “Excellent” or “Very Good”

Using this dataset, do or answer the following:

How many unique locations are included in the dataset?

Is every state represented? What state is observed the most?

In 2002, what is the median of the “Excellent” response value?

Make a histogram of “Excellent” response values in the year 2002.

Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.
